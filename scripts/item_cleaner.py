import csv
import pandas as pd
from collections import defaultdict

def generate_avoid_list(original_csv, modified_csv, output_csv):
    """ç”Ÿæˆé¿å‘åˆ—è¡¨ï¼šå¯¹æ¯”ä¸¤ä¸ªCSVçš„å·®å¼‚"""
    print("â³ æ­£åœ¨åˆ†æCSVå·®å¼‚...")
    
    # è¯»å–CSVæ–‡ä»¶
    try:
        df_orig = pd.read_csv(original_csv)
        df_mod = pd.read_csv(modified_csv)
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        return
    
    # åŸºäºIDåˆ›å»ºç´¢å¼•
    orig_dict = {row['id']: row for _, row in df_orig.iterrows()}
    mod_dict = {row['id']: row for _, row in df_mod.iterrows()}
    
    # è¯†åˆ«å·®å¼‚é¡¹
    pitfalls = []
    for item_id, orig_row in orig_dict.items():
        if item_id not in mod_dict:
            pitfalls.append(orig_row)  # å®Œå…¨åˆ é™¤çš„é¡¹
        else:
            mod_row = mod_dict[item_id]
            # æ£€æŸ¥å…³é”®å­—æ®µå·®å¼‚
            diff_fields = []
            for col in ['alphabet', 'han_num', 'chinese_name']:
                if orig_row[col] != mod_row[col]:
                    diff_fields.append(col)
            if diff_fields:
                pitfalls.append({**orig_row, 'modified_fields': ','.join(diff_fields)})
    
    # ä¿å­˜é¿å‘åˆ—è¡¨
    if pitfalls:
        pd.DataFrame(pitfalls).to_csv(output_csv, index=False)
        print(f"âœ… å·²ç”Ÿæˆé¿å‘åˆ—è¡¨: {output_csv} ({len(pitfalls)}ä¸ªé£é™©é¡¹)")
    else:
        print("â„¹ï¸ æœªå‘ç°éœ€è¦é¿å‘çš„å·®å¼‚é¡¹")

def auto_remove_pitfalls(original_csv, avoid_csv, output_csv):
    """è‡ªåŠ¨åˆ é™¤é¿å‘é¡¹"""
    print("â³ æ­£åœ¨æ‰§è¡Œè‡ªåŠ¨åˆ å‘...")
    
    # è¯»å–æ•°æ®
    df_orig = pd.read_csv(original_csv)
    df_avoid = pd.read_csv(avoid_csv)
    
    # åˆ›å»ºé¿å‘IDç´¢å¼•
    avoid_ids = set(df_avoid['id'])
    avoid_dict = {row['id']: row for _, row in df_avoid.iterrows()}
    
    # æ‰§è¡Œæ¸…ç†
    success_removed = []
    unmatched = []
    
    cleaned_rows = []
    for _, row in df_orig.iterrows():
        item_id = row['id']
        if item_id in avoid_ids:
            # è®°å½•æˆåŠŸç§»é™¤é¡¹
            risk_data = avoid_dict[item_id]
            modified_fields = risk_data.get('modified_fields', 'å®Œå…¨åˆ é™¤')
            success_removed.append({
                'id': item_id,
                'name': risk_data['chinese_name'],
                'risk_type': modified_fields
            })
        else:
            cleaned_rows.append(row)
    
    # æ£€æŸ¥æœªåŒ¹é…é¡¹
    processed_ids = {row['id'] for row in cleaned_rows} | {item['id'] for item in success_removed}
    for item_id in avoid_ids:
        if item_id not in processed_ids:
            unmatched.append({
                'id': item_id,
                'reason': 'åŸå§‹CSVä¸­ä¸å­˜åœ¨æ­¤ID'
            })
    
    # ä¿å­˜æ¸…ç†ç»“æœ
    pd.DataFrame(cleaned_rows).to_csv(output_csv, index=False)
    
    # æ§åˆ¶å°æŠ¥å‘Š
    print("\n=== æ¸…ç†ç»“æœæŠ¥å‘Š ===")
    if success_removed:
        print(f"âœ… æˆåŠŸé¿å‘é¡¹ ({len(success_removed)}ä¸ª):")
        for item in success_removed:
            print(f"   - {item['id']} ({item['name']}) é£é™©ç±»å‹: {item['risk_type']}")
    else:
        print("â„¹ï¸ æœªæ‰¾åˆ°éœ€æ¸…ç†çš„åŒ¹é…é¡¹")
    
    if unmatched:
        print(f"âŒ æœªåŒ¹é…é¡¹ ({len(unmatched)}ä¸ª):")
        for item in unmatched:
            print(f"   - {item['id']}: {item['reason']}")
    
    print(f"\nğŸ’¾ æ¸…ç†åæ–‡ä»¶å·²ä¿å­˜: {output_csv}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Minecraftç‰©å“æ•°æ®é¿å‘å·¥å…·')
    subparsers = parser.add_subparsers(dest='command', required=True)
    
    # generateå‘½ä»¤
    parser_gen = subparsers.add_parser('generate', help='ç”Ÿæˆé¿å‘åˆ—è¡¨')
    parser_gen.add_argument('original', help='åŸå§‹CSVæ–‡ä»¶è·¯å¾„')
    parser_gen.add_argument('modified', help='ä¿®æ”¹åCSVæ–‡ä»¶è·¯å¾„')
    parser_gen.add_argument('output', help='é¿å‘åˆ—è¡¨è¾“å‡ºè·¯å¾„')
    
    # removeå‘½ä»¤
    parser_rm = subparsers.add_parser('remove', help='è‡ªåŠ¨åˆ é™¤é¿å‘é¡¹')
    parser_rm.add_argument('original', help='åŸå§‹CSVæ–‡ä»¶è·¯å¾„')
    parser_rm.add_argument('avoid', help='é¿å‘åˆ—è¡¨æ–‡ä»¶è·¯å¾„')
    parser_rm.add_argument('output', help='æ¸…ç†åè¾“å‡ºè·¯å¾„')
    
    args = parser.parse_args()
    
    if args.command == 'generate':
        generate_avoid_list(args.original, args.modified, args.output)
    elif args.command == 'remove':
        auto_remove_pitfalls(args.original, args.avoid, args.output)
